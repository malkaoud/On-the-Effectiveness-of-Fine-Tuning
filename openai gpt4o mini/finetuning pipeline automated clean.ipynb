{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af97a46f-dd7c-41d7-abc7-2947b521c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.fine_tuning import SupervisedMethod, SupervisedHyperparameters\n",
    "api_key=\"<put your key>\"\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e467b6a-ab1d-44fb-9d89-dbfa405e904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_for_finetuning_jobs(job_ids, api_key, poll_interval=60):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    finished_statuses = {\"succeeded\", \"failed\", \"cancelled\"}\n",
    "    \n",
    "    while True:\n",
    "        statuses = []\n",
    "        for job_id in job_ids:\n",
    "            job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "            statuses.append(job.status)\n",
    "        \n",
    "        if all(status in finished_statuses for status in statuses):\n",
    "            print(\"All jobs finished.\")\n",
    "            return statuses\n",
    "        time.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb208137-223c-44d0-9696-587ab7541fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iterations = 5 #please change to required number\n",
    "jobs = [None] * number_of_iterations\n",
    "\n",
    "for i in range(number_of_iterations):\n",
    "    job = client.fine_tuning.jobs.create(\n",
    "        training_file=\"<put training file id>\",\n",
    "        validation_file=\"<put validation file id>\",\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        method={\n",
    "        \"type\": \"supervised\",\n",
    "        \"supervised\": SupervisedMethod(\n",
    "          hyperparameters=SupervisedHyperparameters(\n",
    "            n_epochs=3,\n",
    "            batch_size=1,\n",
    "            learning_rate_multiplier=1.8,\n",
    "          )\n",
    "        )\n",
    "      }\n",
    "    )\n",
    "    print(job.id)\n",
    "    jobs[i] = job.id\n",
    "    \n",
    "wait_for_finetuning_jobs(jobs, api_key, poll_interval=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39c792fb-bf3d-4ec2-b9c4-140dfe6844e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_model_name(job_id, api_key):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    return job.fine_tuned_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21581478-f2bd-4b21-902d-a49c486f716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "task_script = \"ArSAS_GPT4o_ZeroShot*\" #you can change it to \"ArSarcasm_GPT4o_ZeroShot*\" or \"ASND_GPT4o_ZeroShot*\" depending on the task\n",
    "models = [get_output_model_name(x,api_key) for x in jobs]\n",
    "OPENAI_API_KEY = api_key\n",
    "WORKING_DIR = \"./\"\n",
    "LOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n",
    "\n",
    "def safe_folder_name(model_name):\n",
    "    date_str = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    base = re.sub(r'[^a-zA-Z0-9._-]', '_', model_name)\n",
    "    return f\"{base}_{date_str}\"\n",
    "\n",
    "def run_bench(model):\n",
    "    folder_name = safe_folder_name(model)\n",
    "    log_file = os.path.join(LOGS_DIR, f\"{folder_name}.log\")\n",
    "\n",
    "    env = os.environ.copy()\n",
    "    env[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "    env[\"OPENAI_MODEL\"] = model\n",
    "\n",
    "    #make sure you downloaded llmebench from https://github.com/qcri/LLMeBench\n",
    "    cmd = [\n",
    "        \"python\", \"-m\", \"llmebench\",\n",
    "        \"--filter\", task_script,\n",
    "        \"assets/\", folder_name\n",
    "    ]\n",
    "\n",
    "    with open(log_file, \"w\") as logf:\n",
    "        logf.write(f\"Running in: {WORKING_DIR}\\n\")\n",
    "        logf.write(f\"Model: {model}\\n\")\n",
    "        logf.flush()\n",
    "        process = subprocess.Popen(\n",
    "            cmd, env=env, cwd=WORKING_DIR,\n",
    "            stdout=logf, stderr=subprocess.STDOUT\n",
    "        )\n",
    "        process.wait()\n",
    "        logf.write(f\"\\nProcess exited with code {process.returncode}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with ThreadPoolExecutor(max_workers=len(models)) as executor:\n",
    "        futures = [executor.submit(run_bench, model) for model in models]\n",
    "        for f in futures:\n",
    "            f.result()  # Raises any exceptions that occurred\n",
    "    print(\"All jobs finished. Check logs in:\", LOGS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23b837-8618-40f8-b5ec-58109afffac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
